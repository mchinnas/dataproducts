names(dat1)
dat1(18:23, 7:15)
names(dat1)
dat1[18:23, 7:15]
dat2 <- dat1[18:23, 7:15]
dat2$zip
dat1$zip
dat$zip
sum(dat$Zip*dat$Ext)
dat$zip
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
download.file(fileUrl, destfile = "restaurants.xlsx", mode = "wb")
rest <- read.xlsx("restaurants.xlsx", 1)
rest <- read.xlsx("restaurants.xlsx", SheetIndex = 1, header = TRUE)
rest <- read.xlsx("restaurants.xlsx", Sheetindex = 1, header = TRUE)
rest <- read.xlsx("restaurants.xlsx", SheetIndex = 1, header = TRUE)
download.file(fileUrl, destfile = "restaurants.xlsx", method = "curl")
download.file(fileUrl, destfile = "restaurants.xlsx", mod = 1)
download.file(fileUrl, destfile = "restaurants.xlsx", mode = "wb")
rest <- read.xlsx("restaurants.xlsx", SheetIndex = 1, header = TRUE)
library(XML)
install.packages(XML)
install.packages("XML")
library(XML)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(fileUrl, useInternal = TRUE)
fileUrl <- "http://www.w3schools.com/xml/sample.xml"
doc <- xmlTreeParse(fileUrl, useInternal = TRUE)
fileUrl <- "http://www.w3schools.com/xml/simple.xml"
doc <- xmlTreeParse(fileUrl, useInternal = TRUE)
names(doc)
rootNode <- xmlRoot(doc)
names(rootNote)
xmlName(rootNote)
names(rootNode)
xmlName(rootNode)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(fileUrl, useInternal = TRUE)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
fileUrl <- "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(fileUrl, useInternal = TRUE)
doc
xpathSApply(doc, "//zip-code", xmlValue)
xpathSApply(doc, "//zipcode", xmlValue)
zipcode <- xpathSApply(doc, "//zipcode", xmlValue)
zipcode[zipcode$zipcode == 21231]
zipcode[zipcode$zipcode == "21231"]
zipcode1 <- xpathSApply(doc, "//zipcode", xmlValue)
zipcode1[zipcode1$zipcode == "21231"]
zipcode1$zipcode == "21231"
names(zipcode1)
class(zipcode1)
attributes(zipcode1)
zipcode[zipcode == "21231"]
? count
sum(zipcode[zipcode == "21231"])
table(zipcode[zipcode == "21231"])
tables()
table()
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fileUrl, destFile = "idahoData")
download.file(fileUrl, destFile = "idahoData.csv")
download.file(fileUrl, destFile = "idahoData.csv", mode = "wb")
download.file(fileUrl, destfile = "idahoData.csv", mode = "wb")
?fread
?fread()
fread(idahoData.csv)
library(data.table)
install.packages(data.table)
install.packages("data.table")
fread(idahoData.csv)
library(data.table)
fread(idahoData.csv)
ls
tables()
dir
dir()
fread(idahoData.csv)
?fread()
fread("idahoData.csv")
DT <- fread("idahoData.csv")
tapply(DT$pwgtp15,DT$SEX,mean)
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(fread("idahoData.csv"))
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2])
rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]
tapply(DT$pwgtp15,DT$SEX,mean)
?data.table()
?data.frame()
head("idahoData.csv")
header("idahoData.csv")
head(DT)
system.time(DT[,mean(pwgtp15),by=SEX])
system.time()
system.time(
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
system.time("mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)")
system.time(mean(DT[DT$SEX==1,]$pwgtp15)
)
system.time(mean(DT[DT$SEX==2,]$pwgtp15))
system.time(mean(DT$pwgtp15,by=DT$SEX))
system.time(rowMeans(DT)[DT$SEX==1])
system.time(rowMeans(DT)[DT$SEX==1]))
system.time(rowMeans(DT)[DT$SEX==1])
rowMeans(DT)[DT$SEX==1]
sapply(split(DT$pwgtp15,DT$SEX),mean)
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
? system.time()
system.time(rowMeans(DT)[DT$SEX==1])
rowMeans(DT)[DT$SEX==1]
rowMeans(DT)[DT$SEX==1];
rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]
tapply(DT$pwgtp15,DT$SEX,mean)
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(replicate(1000, tapply(DT$pwgtp15,DT$SEX,mean))
)
sapply(split(DT$pwgtp15,DT$SEX),mean)
system.time(replicate(1000, sapply(split(DT$pwgtp15,DT$SEX),mean)))
rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]
rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2];
mean(DT$pwgtp15,by=DT$SEX)
system.time(replicate(1000,mean(DT$pwgtp15,by=DT$SEX)))
DT[,mean(pwgtp15),by=SEX]
system.tim(replicate(1000, DT[,mean(pwgtp15),by=SEX]))
system.time(replicate(1000, DT[,mean(pwgtp15),by=SEX]))
tables()
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15);
system.time(replicate(1000, mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)))
system.time(replicate(1000, mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15;)))
system.time(replicate(1000, mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15);))
system.time(replicate(1000, mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)))
system.time(replicate(1000, {mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15;})))
system.time(replicate(1000, {mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15})))
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15);)
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
system.time(mean(DT[DT$SEX==1,]$pwgtp15))
system.time(replicate(1000, mean(DT[DT$SEX==1,]$pwgtp15)))
tables(DT$pwgtp15)
DT[, .N, by=pwgtp15]
DT[, .N, by=SEX]
?tapply()
sapply()
?sapply()
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
read.csv(fileUrl, destfile="community.csv")
read.csv(fileUrl, destFile="community.csv", mode="wb")
download.file(fileUrl, destfile = "community.csv", mode="wb")
communityData <- read.csv(cummunity.csv)
communityData <- read.csv("cummunity.csv:)
)
""
communityData <- read.csv("cummunity.csv")
communityData <- read.csv("community.csv")
communityData[communityData$VAL == 24]
communityData[, communityData$VAL == 24]
head(communityData)
communityData[, communityData$VAL > 23]
houseVal <- communityData[, communityData$VAL3]
houseVal <- houseVal[!is.na(houseVal)]
houseVal[houseVal$VAL == 24]
houseVal
houseVal <- communityData[, communityData$VAL]
communityData <- read.csv("community.csv")
houseVal <- communityData[, communityData$VAL]
houseVal <- communityData[, !is.na(communityData$VAL)]
head(communityData)
colVal <- communityData$VAL
colVal1 <- colVal[!is.na(colVal)]
head(colVal1)
?sum()
sum(colVal, na.rm = TRUE)
sum(colVal1[colVal1 == 24])
1272/24
fileUrl <- "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx"
download.file (fileUrl, destfile="gasbal.xlsx")
gasData <- read.xlsx("gasbal.xlsx", sheetIndex=1, header=TRUE)
library("xlsx")
gasData <- read.xlsx("gasbal.xlsx", sheetIndex=1, header=TRUE)
library(rjava)
library(rJava)
gasData <- read.xlsx("gasbal.xlsx", sheetIndex=1, header=TRUE)
install.packages(xlsx)
install.packages("xlsx")
gasData <- read.xlsx("gasbal.xlsx", sheetIndex=1, header=TRUE)
Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jre7')
gasData <- read.xlsx("gasbal.xlsx", sheetIndex=1, header=TRUE)
Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jdk1.7.0_67\\bin')
gasData <- read.xlsx("gasbal.xlsx", sheetIndex=1, header=TRUE)
dat <- read.xlsx("gasbal.xlsx", sheetIndex = 1, rowIndex = rowIndex, colIndex = colIndex)
install.packages("xlsx")
quit()
NEI <- readRDS("summarySCC_PM25.rds")
SCC <- readRDS("Source_Classification_Code.rds")
#head(NEI)
#str(NEI)
#head(SCC)
#str(SCC)
# Draw the histogram.
#hist(NEI$Emissions, col = "red")
#plot(NEI$year, NEI$Emissions, type = "l",
#     ylab = "Emissions", xlab = "Year")
emissions <- array(data = tapply(NEI$Emissions, NEI$year, sum))
# Collect all the intervals
years <- array(unique(NEI$year))
# Construct a data frame using the average.steps and intervals vector
df <- data.frame(Emissions = emissions, year = years)
plot(df$year, df$Emissions, type = "l", xlab = "Year", ylab = "Emissions in tons")
#plot#2
baltimore.df <- subset(NEI, fips = "24510")
emissions <- array(data = tapply(baltimore.df $Emissions, baltimore.df $year, sum))
# Collect all the intervals
years <- array(unique(baltimore.df $year))
df <- data.frame(Emissions = emissions, year = years)
plot(baltimore.df$year, baltimore.df$Emissions, type = "l", xlab = "Year", ylab = "Emissions in tons")
# Calculate the aggregate of average of the steps per interval per weekday or weekend
aggregate.data <- aggregate(Emissions ~ year + type, NEI, su)
# Draw the panel plot
ggplot(aggregate.data, aes(year, Emissions)) + geom_line() + facet_wrap(~ type, ncol = 2)
q(.975, 8)
4/3
q(.975,9)
getwd()
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
str(train)
str(vowel.train)
mod1 <- train(y ~ ., method = "rf", data=vowel.train)
library(caret)
mod1 <- train(y ~ ., method = "rf", data=vowel.train)
setseed(33833)
setSeed(33833)
setSead(33833)
set.seed(33833)
mod1 <- train(y ~ ., method = "rf", data=vowel.train)
mod2 <- train(y ~ ., method = "gbm", data=vowel.train)
mod2 <- train(y ~ ., method = "gbm", data=vowel.train)
pred1 <- predict(mod1, testing)
pred1 <- predict(mod1, vowel.test)
pred2 <- predict(mod2, vowel.test)
predDF <- data.frame(pred1, pred2, testing$y)
predDF <- data.frame(pred1, pred2, vowel.test$y)
comModFit <- train(y ~ ., method = "gam", data = predDF)
str(vowel.test)
predDF <- data.frame(pred1, pred2, y = vowel.test$y)
comModFit <- train(y ~ ., method = "gam", data = predDF)
combPred <- predict(comModFit, predDF)
sqrt(sum((pred1-testing$wage)^2)
)
sqrt(sum((pred1-vowel.test$wage)^2))
sqrt(sum((pred1-vowel.test$y)^2))
sqrt(sum((pred2-vowel.test$y)^2))
sqrt(sum((combPred-vowel.test$y)^2))
mod1 <- train(y ~ ., method = "rf", data=vowel.train, trControl = trainControl(method="cv"), number = 3)
pred1 <- predict(mod1, vowel.test)
pred2 <- predict(mod2, vowel.test)
predDF <- data.frame(pred1, pred2, y = vowel.test$y)
comModFit <- train(y ~ ., method = "gam", data = predDF)
combPred <- predict(comModFit, predDF)
sqrt(sum((pred1-vowel.test$y)^2))
pred2 <- predict(mod2, vowel.test)
sqrt(sum((pred2-vowel.test$y)^2))
print(combPred)
print(pred1)
summary(pred1)
print(pred1$finalModel)
print(mod1$finalModel)
confusionMatrix(pred1,vowel.test$y)
print(predict1)
print(pred1)
confusionMatrix(pred2,vowel.test$y)
confusionMatrix(pred2,pred2$y)
confusionMatrix(pred2,vowel.test$y)
pred1 <- predict(mod1, vowel.test)
confusionMatrix(pred2,vowel.test$y)
confusionMatrix(pred1,vowel.test$y)
set.seed(33833)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
mod1 <- train(y ~ ., method = "rf", data=vowel.train)
pred1 <- predict(mod1, vowel.test)
confusionMatrix(data=pred1, vowel.testt$y)
confusionMatrix(data=pred1, vowel.test$y)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
mod1 <- train(y ~ ., method = "rf", data=vowel.train)
pred1 <- predict(mod1, vowel.test)
confusionMatrix(data=pred1, vowel.test$y)
mod2 <- train(y ~ ., method = "gbm", data=vowel.train)
pred2 <- predict(mod2, vowel.test)
confusionMatrix(data=pred2, vowel.test$y)
predDF <- data.frame(pred1, pred2, vowel.test$y)
comModFit <- train(y ~ ., method = "gam", data = predDF)
combPred <- predict(comModFit, predDF)
confusionMatrix(data=combpred, predDF$y)
predDF <- data.frame(pred1, pred2, vowel.test$y)
comModFit <- train(y ~ ., method = "gam", data = predDF)
predDF <- data.frame(pred1, pred2, y = vowel.test$y)
comModFit <- train(y ~ ., method = "gam", data = predDF)
combPred <- predict(comModFit, predDF)
confusionMatrix(data=combpred, predDF$y)
confusionMatrix(data=combPred, predDF$y)
combPred <- predict(comModFit, vowel.test)
confusionMatrix(data=combPred, predDF$y)
library(ElemStatLearn)
library(randomForest)
library(caret)
data(vowel.train)
data(vowel.test)
# Set the variable y to be a factor variable in both the training and test set.
# Then set the seed to 33833. Fit (1) a random forest predictor relating the
# factor variable y to the remaining variables and (2) a boosted predictor using
# the "gbm" method. Fit these both with the train() command in the caret package.
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
# create models
fit1 <- train(y ~ ., data = vowel.train, method = "rf", trControl = trainControl(number = 4))
fit2 <- train(y ~ ., data = vowel.train, method = "gbm")
# predict test
predict1 <- predict(fit1, newdata = vowel.test)
predict2 <- predict(fit2, newdata = vowel.test)
# combine predictions
DF_combined <- data.frame(predict1, predict2, y = vowel.test$y)
fit_combined <- train(y ~ ., data = DF_combined, method = "gam")
predict3 <- predict(fit_combined, newdata = vowel.test)
c1 <- confusionMatrix(predict1, vowel.test$y)
c2 <- confusionMatrix(predict2, vowel.test$y)
c3 <- confusionMatrix(predict3, DF_combined$y)
c1
c2
c3
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
mod1 <- train(diagnosis ~ ., method = "rf", data=training)
pred1 <- predict(mod1, testing)
confusionMatrix(data=pred1, testing$diagnosis)
mod2 <- train(diagnosis ~ ., method = "gbm", data=training)
pred2 <- predict(mod2, testing)
confusionMatrix(data=pred2, testing$diagnosis)
mod3 <- train(diagnosis ~ ., method = "lda", data=training)
pred3 <- predict(mod3, testing)
confusionMatrix(data=pred3, testing$diagnosis)
DF_combined <- data.frame(pred1, pred2, pred3, diagnosis = testing$diagnosis)
fit_combined <- train(diagnosis ~ ., data = DF_combined, method = "gam")
predict3 <- predict(fit_combined, newdata = testing)
c1 <- confusionMatrix(pred1, testing$diagnosis)
c2 <- confusionMatrix(pred2, testing$diagnosis)
c3 <- confusionMatrix(pred3, testing$diagnosis)
c4 <- confusionMatrix(predict3, DF_combined$diagnosis)
c1
c2
c3
c4
print(paste(c1$overall[1], c2$overall[1], c3$overall[1], c4$overall[1]))
?lasso()
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
str(concrete)
set.seed(233)
mod1 <- train(CompressiveStrength ~ ., method = "lasso", data=training)
set.seed(233)
mod1 <- train(CompressiveStrength ~ ., method = "lasso", data=training)
pred1 <- predict(mod1, testing)
confusionMatrix(data=pred1, testing$CompressiveStrength)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
concrete$CompressiveStrength <- factor(concrete$CompressiveStrength)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
mod1 <- train(CompressiveStrength ~ ., method = "lasso", data=training)
pred1 <- predict(mod1, testing)
confusionMatrix(data=pred1, testing$CompressiveStrength)
mod1 <- train(CompressiveStrength ~ ., method = "rf", data=training)
mod1 <- train(CompressiveStrength ~ ., method = "lasso", data=training)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
concrete$CompressiveStrength <- factor(concrete$CompressiveStrength)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
library(AppliedPredictiveModeling)
library(caret)
library(rattle)
library(forecast)
library(lubridate)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
concrete$CompressiveStrength <- factor(concrete$CompressiveStrength)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
mod1 <- train(CompressiveStrength ~ ., method = "lasso", data=training)
model = train(CompressiveStrength ~ ., method = 'lasso', data = training)
install.packages("e1071")
install.packages("e1071")
library(e1071)
model = train(CompressiveStrength ~ ., method = 'lasso', data = training)
lasso <- train(CompressiveStrength ~ ., data = concrete, method = "lasso")
getwd()
library(lubridate)  # For year() function below
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
install.packages("lubridate")
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
getwd()
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(lubridate)
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
?bats()
model = bats(tstrain)
install.packages("forcast")
install.packages(forcast)
library(forcast)
install.packages(forcast)
install.packages("forcast")
model = bats(tstrain)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
model = svm(CompressiveStrength ~ ., data = training)
model
pred = predict(model, testing)
RMSE = sqrt(sum((pred - testing$CompressiveStrength)^2))
predins = predict(model, training)
RMSEins = sqrt(sum((predins - training$CompressiveStrength)^2))
RMSE
RMSEins
fit <- train(CompressiveStrength ~ ., data = training, method = "svmRadial")
fit <- train(CompressiveStrength ~ ., data = training, method = "svmRadial")
prediction <- predict(fit, testing)
accuracy(prediction, testing$CompressiveStrength)
library(e1071)
library(caret)
accuracy(prediction, testing$CompressiveStrength)
install.package("shiny")
install.packages("shiny")
library(shiny)
library(manipulate)
?slider
?manipulate
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
manipulate(myPlot(s), slider = x(0, 2, step = 0.1))
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
manipulate(myPlot(s), s = slider(0, 2, step = 0.1))
manipulate(plot(1:x), x = slider(5, 10))
install.packages("rCharts")
data(airquality)
library(rCharts)
d <- data.frame(airquality, stringsAsFactors = FALSE) print(d)
d <- data.frame(airquality, stringsAsFactors = FALSE)
print(d)
head(airquality)
airquality
getwd()
setwd("C:/CourseraProject/DataProducts-09")
getwd()
install.packages("shiny")
library(shiny)
install.packages("Rtools")
library(Rtools)
install.packages("Rtools")
ap <- available.packages()
Sys.getenv('PATH')
